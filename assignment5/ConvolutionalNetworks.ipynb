{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Convolutional Networks\n",
    "In this assignment we will implement several layer types that are used in convolutional networks. We will then use these layers to train a convolutional network on a small subset of CIFAR-10 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# As usual, a bit of setup\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lib.classifiers.cnn import *\n",
    "from lib.data_utils import get_CIFAR10_data\n",
    "from lib.gradient_check import eval_numerical_gradient_array, eval_numerical_gradient\n",
    "from lib.layers import *\n",
    "from lib.solver import Solver\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val:  (1000L, 3L, 32L, 32L)\n",
      "X_train:  (49000L, 3L, 32L, 32L)\n",
      "X_test:  (1000L, 3L, 32L, 32L)\n",
      "y_val:  (1000L,)\n",
      "y_train:  (49000L,)\n",
      "y_test:  (1000L,)\n"
     ]
    }
   ],
   "source": [
    "# Load the (preprocessed) CIFAR10 data.\n",
    "\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in data.items():\n",
    "  print('%s: ' % k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Convolution: Forward pass\n",
    "The core of a convolutional network is the convolution operation. In the file `lib/layers.py`, implement the forward pass for the convolution layer in the function `conv_forward`. \n",
    "\n",
    "You don't have to worry too much about efficiency; just write the code in whatever way you find most clear.\n",
    "\n",
    "You can test your implementation by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing conv_forward\n",
      "difference:  2.21214764175e-08\n"
     ]
    }
   ],
   "source": [
    "x_shape = (2, 3, 4, 4)\n",
    "w_shape = (3, 3, 4, 4)\n",
    "x = np.linspace(-0.1, 0.5, num=np.prod(x_shape)).reshape(x_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=np.prod(w_shape)).reshape(w_shape)\n",
    "b = np.linspace(-0.1, 0.2, num=3)\n",
    "\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "out, _ = conv_forward(x, w, b, conv_param)\n",
    "correct_out = np.array([[[[-0.08759809, -0.10987781],\n",
    "                           [-0.18387192, -0.2109216 ]],\n",
    "                          [[ 0.21027089,  0.21661097],\n",
    "                           [ 0.22847626,  0.23004637]],\n",
    "                          [[ 0.50813986,  0.54309974],\n",
    "                           [ 0.64082444,  0.67101435]]],\n",
    "                         [[[-0.98053589, -1.03143541],\n",
    "                           [-1.19128892, -1.24695841]],\n",
    "                          [[ 0.69108355,  0.66880383],\n",
    "                           [ 0.59480972,  0.56776003]],\n",
    "                          [[ 2.36270298,  2.36904306],\n",
    "                           [ 2.38090835,  2.38247847]]]])\n",
    "\n",
    "# Compare your output to ours; difference should be around 2e-8\n",
    "print('Testing conv_forward')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Convolution: Backward pass\n",
    "Implement the backward pass for the convolution operation in the function `conv_backward` in the file `lib/layers.py`. Again, you don't need to worry too much about computational efficiency.\n",
    "\n",
    "When you are done, run the following to check your backward pass with a numeric gradient check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing conv_backward function\n",
      "dx error:  1.15980316116e-08\n",
      "dw error:  2.24710943494e-10\n",
      "db error:  3.3726400665e-11\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(4, 3, 5, 5)\n",
    "w = np.random.randn(2, 3, 3, 3)\n",
    "b = np.random.randn(2,)\n",
    "dout = np.random.randn(4, 2, 5, 5)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: conv_forward(x, w, b, conv_param)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: conv_forward(x, w, b, conv_param)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: conv_forward(x, w, b, conv_param)[0], b, dout)\n",
    "\n",
    "out, cache = conv_forward(x, w, b, conv_param)\n",
    "dx, dw, db = conv_backward(dout, cache)\n",
    "\n",
    "# Your errors should be around 1e-8'\n",
    "print('Testing conv_backward function')\n",
    "print('dx error: ', rel_error(dx, dx_num))\n",
    "print('dw error: ', rel_error(dw, dw_num))\n",
    "print('db error: ', rel_error(db, db_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Max pooling: Forward\n",
    "Implement the forward pass for the max-pooling operation in the function `max_pool_forward` in the file `lib/layers.py`. Again, don't worry too much about computational efficiency.\n",
    "\n",
    "Check your implementation by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing max_pool_forward function:\n",
      "difference:  4.16666651573e-08\n"
     ]
    }
   ],
   "source": [
    "x_shape = (2, 3, 4, 4)\n",
    "x = np.linspace(-0.3, 0.4, num=np.prod(x_shape)).reshape(x_shape)\n",
    "pool_param = {'pool_width': 2, 'pool_height': 2, 'stride': 2}\n",
    "\n",
    "out, _ = max_pool_forward(x, pool_param)\n",
    "\n",
    "correct_out = np.array([[[[-0.26315789, -0.24842105],\n",
    "                          [-0.20421053, -0.18947368]],\n",
    "                         [[-0.14526316, -0.13052632],\n",
    "                          [-0.08631579, -0.07157895]],\n",
    "                         [[-0.02736842, -0.01263158],\n",
    "                          [ 0.03157895,  0.04631579]]],\n",
    "                        [[[ 0.09052632,  0.10526316],\n",
    "                          [ 0.14947368,  0.16421053]],\n",
    "                         [[ 0.20842105,  0.22315789],\n",
    "                          [ 0.26736842,  0.28210526]],\n",
    "                         [[ 0.32631579,  0.34105263],\n",
    "                          [ 0.38526316,  0.4       ]]]])\n",
    "\n",
    "# Compare your output with ours. Difference should be around 1e-8.\n",
    "print('Testing max_pool_forward function:')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Max pooling: Backward\n",
    "Implement the backward pass for the max-pooling operation in the function `max_pool_backward` in the file `lib/layers.py`. You don't need to worry about computational efficiency.\n",
    "\n",
    "Check your implementation with numeric gradient checking by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing max_pool_backward function:\n",
      "dx error:  3.27562514223e-12\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(3, 2, 8, 8)\n",
    "dout = np.random.randn(3, 2, 4, 4)\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: max_pool_forward(x, pool_param)[0], x, dout)\n",
    "\n",
    "out, cache = max_pool_forward(x, pool_param)\n",
    "dx = max_pool_backward(dout, cache)\n",
    "\n",
    "# Your error should be around 1e-12\n",
    "print('Testing max_pool_backward function:')\n",
    "print('dx error: ', rel_error(dx, dx_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Convolutional \"sandwich\" layers\n",
    "Previously we introduced the concept of \"sandwich\" layers that combine multiple operations into commonly used patterns. In the file `lib/layer_utils.py` you will find sandwich layers that implement a few commonly used patterns for convolutional networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing conv_relu_pool\n",
      "dx error:  1.73860048794e-08\n",
      "dw error:  4.34119246447e-09\n",
      "db error:  7.50349004263e-10\n"
     ]
    }
   ],
   "source": [
    "from lib.layer_utils import conv_relu_pool_forward, conv_relu_pool_backward\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(2, 3, 16, 16)\n",
    "w = np.random.randn(3, 3, 3, 3)\n",
    "b = np.random.randn(3,)\n",
    "dout = np.random.randn(2, 3, 8, 8)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "out, cache = conv_relu_pool_forward(x, w, b, conv_param, pool_param)\n",
    "dx, dw, db = conv_relu_pool_backward(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], b, dout)\n",
    "\n",
    "print('Testing conv_relu_pool')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing conv_relu:\n",
      "dx error:  2.97057010074e-09\n",
      "dw error:  4.61360428081e-10\n",
      "db error:  1.57689947927e-10\n"
     ]
    }
   ],
   "source": [
    "from lib.layer_utils import conv_relu_forward, conv_relu_backward\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(2, 3, 8, 8)\n",
    "w = np.random.randn(3, 3, 3, 3)\n",
    "b = np.random.randn(3,)\n",
    "dout = np.random.randn(2, 3, 8, 8)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "\n",
    "out, cache = conv_relu_forward(x, w, b, conv_param)\n",
    "dx, dw, db = conv_relu_backward(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: conv_relu_forward(x, w, b, conv_param)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: conv_relu_forward(x, w, b, conv_param)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: conv_relu_forward(x, w, b, conv_param)[0], b, dout)\n",
    "\n",
    "print('Testing conv_relu:')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Three-layer ConvNet\n",
    "Now that you have implemented all the necessary layers, we can put them together into a simple convolutional network.\n",
    "\n",
    "Open the file `lib/classifiers/cnn.py` and complete the implementation of the `ThreeLayerConvNet` class. Run the following cells to help you debug:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Sanity check loss\n",
    "After you build a new network, one of the first things you should do is sanity check the loss. When we use the softmax loss, we expect the loss for random weights (and no regularization) to be about `log(C)` for `C` classes. When we add regularization this should go up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss (no regularization):  2.30258563876\n",
      "Initial loss (with regularization):  2.5095647794\n"
     ]
    }
   ],
   "source": [
    "model = ThreeLayerConvNet()\n",
    "\n",
    "N = 50\n",
    "X = np.random.randn(N, 3, 32, 32)\n",
    "y = np.random.randint(10, size=N)\n",
    "\n",
    "loss, grads = model.loss(X, y)\n",
    "print('Initial loss (no regularization): ', loss)\n",
    "\n",
    "model.reg = 0.5\n",
    "loss, grads = model.loss(X, y)\n",
    "print('Initial loss (with regularization): ', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Gradient check\n",
    "After the loss looks reasonable, use numeric gradient checking to make sure that your backward pass is correct. When you use numeric gradient checking you should use a small amount of artifical data and a small number of neurons at each layer. Note: correct implementations may still have relative errors up to 1e-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 max relative error: 3.053965e-04\n",
      "W2 max relative error: 1.822723e-02\n",
      "W3 max relative error: 3.422399e-04\n",
      "b1 max relative error: 3.397321e-06\n",
      "b2 max relative error: 2.517459e-03\n",
      "b3 max relative error: 9.711800e-10\n"
     ]
    }
   ],
   "source": [
    "num_inputs = 2\n",
    "input_dim = (3, 16, 16)\n",
    "reg = 0.0\n",
    "num_classes = 10\n",
    "np.random.seed(231)\n",
    "X = np.random.randn(num_inputs, *input_dim)\n",
    "y = np.random.randint(num_classes, size=num_inputs)\n",
    "\n",
    "model = ThreeLayerConvNet(num_filters=3, filter_size=3,\n",
    "                          input_dim=input_dim, hidden_dim=7,\n",
    "                          dtype=np.float64)\n",
    "loss, grads = model.loss(X, y)\n",
    "for param_name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, model.params[param_name], verbose=False, h=1e-6)\n",
    "    e = rel_error(param_grad_num, grads[param_name])\n",
    "    print('%s max relative error: %e' % (param_name, rel_error(param_grad_num, grads[param_name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Overfit small data\n",
    "Another thing we can do in order to check our implementation is to train a model with just a few training samples. You should be able to overfit small datasets, which will result in very high training accuracy and comparatively low validation accuracy. \n",
    "\n",
    "It takes a long time to run this part due to the naive implementation of conv and pooling layers. You may take a break and check your plots later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 30) loss: 2.283650\n",
      "(Epoch 0 / 15) train acc: 0.220000; val_acc: 0.105000\n",
      "(Iteration 2 / 30) loss: 2.200124\n",
      "(Epoch 1 / 15) train acc: 0.380000; val_acc: 0.140000\n",
      "(Iteration 3 / 30) loss: 2.047663\n",
      "(Iteration 4 / 30) loss: 2.189709\n",
      "(Epoch 2 / 15) train acc: 0.340000; val_acc: 0.170000\n",
      "(Iteration 5 / 30) loss: 1.933008\n",
      "(Iteration 6 / 30) loss: 1.772877\n",
      "(Epoch 3 / 15) train acc: 0.380000; val_acc: 0.202000\n",
      "(Iteration 7 / 30) loss: 1.786161\n",
      "(Iteration 8 / 30) loss: 1.532846\n",
      "(Epoch 4 / 15) train acc: 0.440000; val_acc: 0.153000\n",
      "(Iteration 9 / 30) loss: 1.861550\n",
      "(Iteration 10 / 30) loss: 1.501285\n",
      "(Epoch 5 / 15) train acc: 0.500000; val_acc: 0.142000\n",
      "(Iteration 11 / 30) loss: 1.363615\n",
      "(Iteration 12 / 30) loss: 1.163014\n",
      "(Epoch 6 / 15) train acc: 0.720000; val_acc: 0.162000\n",
      "(Iteration 13 / 30) loss: 1.146968\n",
      "(Iteration 14 / 30) loss: 0.692165\n",
      "(Epoch 7 / 15) train acc: 0.700000; val_acc: 0.159000\n",
      "(Iteration 15 / 30) loss: 1.006953\n",
      "(Iteration 16 / 30) loss: 1.154513\n",
      "(Epoch 8 / 15) train acc: 0.840000; val_acc: 0.184000\n",
      "(Iteration 17 / 30) loss: 0.876306\n",
      "(Iteration 18 / 30) loss: 0.951437\n",
      "(Epoch 9 / 15) train acc: 0.860000; val_acc: 0.169000\n",
      "(Iteration 19 / 30) loss: 0.400211\n",
      "(Iteration 20 / 30) loss: 0.609630\n",
      "(Epoch 10 / 15) train acc: 0.900000; val_acc: 0.193000\n",
      "(Iteration 21 / 30) loss: 0.618421\n",
      "(Iteration 22 / 30) loss: 0.514996\n",
      "(Epoch 11 / 15) train acc: 0.900000; val_acc: 0.181000\n",
      "(Iteration 23 / 30) loss: 0.207564\n",
      "(Iteration 24 / 30) loss: 0.328140\n",
      "(Epoch 12 / 15) train acc: 0.880000; val_acc: 0.180000\n",
      "(Iteration 25 / 30) loss: 0.801196\n",
      "(Iteration 26 / 30) loss: 0.237533\n",
      "(Epoch 13 / 15) train acc: 0.960000; val_acc: 0.187000\n",
      "(Iteration 27 / 30) loss: 0.210617\n",
      "(Iteration 28 / 30) loss: 0.192142\n",
      "(Epoch 14 / 15) train acc: 0.940000; val_acc: 0.198000\n",
      "(Iteration 29 / 30) loss: 0.152861\n",
      "(Iteration 30 / 30) loss: 0.096335\n",
      "(Epoch 15 / 15) train acc: 1.000000; val_acc: 0.197000\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "num_train = 50\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "model = ThreeLayerConvNet(num_filters=5, filter_size=5, hidden_dim=50, weight_scale=1e-2)\n",
    "\n",
    "solver = Solver(model, small_data,\n",
    "                num_epochs=15, batch_size=25,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=1)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Plotting the loss, training accuracy, and validation accuracy should show clear overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAHjCAYAAACNTANBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xl8lOW99/HvLwtk2LKwJwGCgigIggaK1bZWrbhVqK1b\n9bH2aLFVW9tzSg+2PdX69Bw95Zye2lOXx6q1tlbrGmm1pS64VyEQZBVBFsmEJZCFLYEs1/PHTCAJ\nA5kkc+ee5fN+vfJK5p57Zn4Z5xW/XPd1/S5zzgkAAAD+SfO7AAAAgFRHIAMAAPAZgQwAAMBnBDIA\nAACfEcgAAAB8RiADAADwGYEMAADAZwQyAAAAnxHIAAAAfJbhdwGdNWjQIFdUVOR3GQAAAB1asmTJ\nTufc4I7OS7hAVlRUpNLSUr/LAAAA6JCZbY7mPC5ZAgAA+IxABgAA4DMCGQAAgM8IZAAAAD5LuEn9\nXispC2regrWqqKlTfk5Ac2aM06wpBX6XBQAAkhiBrJWSsqBue26F6hqaJEnBmjrd9twKSSKUAQAA\nz3DJspV5C9YeCmMt6hqaNG/BWp8qAgAAqYBA1kpFTV2njgMAAMQCgayV/JxAp44DAADEAoGslTkz\nximQmd7mWCAzXXNmjPOpIgAAkAqY1N9Ky8R9VlkCAICeRCBrZ9aUgm4HMFpnAACAziCQxVi8tc4g\nHAIAEP+YQxZj8dQ6oyUcBmvq5HQ4HJaUBXu8FgAAcHQEshiLp9YZ8RQOAQDA0RHIYiyeWmfEUzgE\nAABHRyCLsXhqnRFP4RAAABwdgSzGZk0p0F2XTlRBTkAmqSAnoLsunejLRPp4CocAAODoWGXpgVi0\nzohVHRJ91QAAiHcEsiQXL+EQAAAcHZcsAQAAfEYgAwAA8BmBDAAAwGfMIYtjbHsEAEBqIJDFqXjb\nExMAAHiHS5Zxim2PAABIHQSyOMW2RwAApA7PApmZjTCzhWa22sxWmdmtEc4xM/uVma03s+VmdqpX\n9SQatj0CACB1eDlC1ijpX5xz4yVNl3SzmY1vd84FksaGv2ZLut/DehIK2x4BAJA6PAtkzrmtzrml\n4Z/3SFojqf1s9JmSHnMh70nKMbPhXtWUSOJpT0wAAOCtHlllaWZFkqZIer/dXQWStrS6XR4+trXd\n42crNIKmkSNHelVm3GHbIwAAUoPnk/rNrJ+kZyV91zm3uyvP4Zx70DlX7JwrHjx4cGwLBAAA8Jmn\ngczMMhUKY487556LcEpQ0ohWtwvDxwAAAFKGZ5cszcwkPSxpjXPuF0c5bb6kW8zsSUmfklTrnNt6\nlHPhI3YNAADAO17OITtD0v+RtMLMloWP/VDSSElyzj0g6SVJF0paL2m/pK97WA+6iF0DAADwlmeB\nzDn3tiTr4Bwn6WavakBsHGvXAAIZAADdR6d+dIhdAwAA8BaBDB1i1wAAALxFIEOH2DUAAABv9Uhj\nWCS2lnlirLI8EqtPAQCxQCBDVNg14EisPgUAxAqXLIEuOtbqUwAAOoNABnQRq08BALFCIAO6iNWn\nAIBYIZABXcTqUwBArDCpHwknXlY2svoUABArBDL0mFgEqXhb2cjqUwBALHDJEj2iJUgFa+rkdDhI\nlZQFO/U8rGwEACQjAhl6RKyCFCsbAQDJiECGHhGrIMXKRgBAMiKQoUfEKkixshEAkIwIZOgRsQpS\ns6YU6K5LJ6ogJyCTVJAT0F2XTmRiPQAgobHKEj0ili0iWNkIAEg2BDL0GIIUAACRcckSAADAZwQy\nAAAAnxHIAAAAfEYgAwAA8BmBDAAAwGcEMgAAAJ8RyAAAAHxGIAMAAPAZgQwAAMBnBDIAAACfEcgA\nAAB8RiADAADwGZuLIyWVlAU1b8FaVdTUKT8noDkzxrHxOQDANwQypJySsqBue26F6hqaJEnBmjrd\n9twKSSKUAQB84dklSzN7xMx2mNnKo9x/lpnVmtmy8NdPvKoFaG3egrWHwliLuoYmzVuw1pd6SsqC\nOuPu1zR67os64+7XVFIW9KUOAIB/vBwhe1TSryU9doxz3nLOXexhDcARKmrqOnXcS4zWAQAkD0fI\nnHNvSqry6vmBrsrPCXTquJfibbQOAOAPv1dZnm5mH5jZX81swtFOMrPZZlZqZqWVlZU9WR+S0JwZ\n4xTITG9zLJCZrjkzxvV4LfE0WgcA8I+fgWyppFHOuVMk/a+kkqOd6Jx70DlX7JwrHjx4cI8ViOQ0\na0qB7rp0ogpyAjJJBTkB3XXpRF8uEcbTaB0AwD++rbJ0zu1u9fNLZnafmQ1yzu30qyakjllTCuJi\njtacGePazCGT/ButAwD4x7dAZmbDJG13zjkzm6bQaN0uv+oB/NASCumJBgCpzbNAZmZPSDpL0iAz\nK5d0u6RMSXLOPSDpK5K+ZWaNkuokXemcc17VA8SreBmtAwD4x7NA5py7qoP7f61QWwwAAICU5vcq\nSwAAgJRHIAMAAPAZe1kCSYDN0gEgsRHIgATH9ksAkPi4ZAkkOLZfAoDERyADEhzbLwFA4iOQAQmO\n7ZcAIPERyIAEF0+bpQMAuoZJ/UCCY/slAEh8BDIgCbD9EgAkNi5ZAgAA+IxABgAA4DMCGQAAgM+i\nCmRmdquZDbCQh81sqZmd53VxAAAAqSDaEbJ/cs7tlnSepMGSvi7pbs+qAgAASCHRBjILf79Q0m+d\ncx+0OgYAAIBuiDaQLTGzvysUyBaYWX9Jzd6VBQAAkDqi7UN2vaTJkjY45/abWZ5Cly0BAADQTdGO\nkJ0uaa1zrsbMrpH0Y0m13pUFAACQOqINZPdL2m9mp0j6gaTNkh7zrCoAvigpC+qMu1/T6Lkv6oy7\nX1NJWdDvkgAgJUR7ybLROefMbKake5xzD5vZ17wsDEDPKikL6rbnVqiuoUmSFKyp023PrZCkTm3L\nVFIWTLp9NZPxdwIQX6IdIdtjZrdJ+j+SXjSzNEmZ3pUFoKfNW7D2UBhrUdfQpHkL1kb9HC2hLlhT\nJ6fDoS6RR9qS8XcCEH+iDWRXSDqgUD+ybZIKJc3zrCoAPa6ipq5TxyOJRaiLN8n4OwGIP1EFsnAI\ne1xStpldLKneOcccMiCJ5OcEOnU8kliEuniTjL8TgPgT7dZJl0taJOkySZdLet/MvuJlYQB61pwZ\n4xTITG9zLJCZrjkzxkX9HLEIdfEmGX8nAPEn2kuWP5I01Tn3NefctZKmSfo378oC0NNmTSnQXZdO\nVEFOQCapICeguy6d2KnJ67EIdfEmGX8nAPEn2lWWac65Ha1u71L0YQ5Agpg1paBbqwdbHptMKxKT\n8XcCEH/MOdfxSWbzJE2S9ET40BWSljvn/tXD2iIqLi52paWlPf2yAAAAnWZmS5xzxR2dF9UImXNu\njpl9WdIZ4UMPOuee706BAAAACIn2kqWcc89KetbDWgAAAFLSMQOZme2RFOmapklyzrkBnlQFAACQ\nQo4ZyJxz/XuqEAAAgFTl2UpJM3vEzHaY2cqj3G9m9iszW29my83sVK9qAZCa2CwdQKLwsnXFo5LO\nP8b9F0gaG/6aLel+D2sBkGLYgxJAIvEskDnn3pRUdYxTZkp6zIW8JynHzIZ7VQ+A1MIelAASiZ/N\nXQskbWl1uzx87AhmNtvMSs2stLKyskeKA5DY2IMSQCKJuu2Fn5xzD0p6UAo1hvW5HAAJID8noGCE\n8JXoe1CWlAXZNQBIQn6OkAUljWh1uzB8DAC6LRn3oGReHJC8/Axk8yVdG15tOV1SrXNuq4/1AEgi\nsdgsPd4wLw5IXp5dsjSzJySdJWmQmZVLul1SpiQ55x6Q9JKkCyWtl7Rf0te9qgVAauruZunxhnlx\nQPLyLJA5567q4H4n6WavXh8Akk2yzosD4O8lSwBAJyTjvDgAIQmxyhIAoEOXX1llCSQfAhkA9IBY\ntatItnlxAEIIZADgsZZ2FS0rJFvaVUgiXAGQxBwyAPAc7SoAdIRABgAeo10FgI4QyADAY0drS0G7\nCgAtCGQA4DHaVQDoCJP6AcBjtKtAZ7GJfOohkAFAD6BdBaLFqtzUxCVLAADiCKtyUxOBDACAOMKq\n3NREIAMAII6wKjc1EcgAAIgjrMpNTUzqBwAgjrAqNzURyAAAiDOsyk09XLIEAADwGSNkAOISjTEB\npBICGYC4Q2NMAKmGS5YA4g6NMQGkGgIZgLhDY0wAqYZABiDu0BgTQKohkAGIOzTGBJBqmNQPIO7Q\nGDMxxGIlLKtpgRACGYC4RGPM+BaLlbCspgUO45IlAKDTYrESltW0wGEEMgBAp8ViJSyraYHDCGQA\ngE6LxUpYVtMChxHIAACdFouVsKymBQ5jUj8AoNNisRKW1bTAYeac87uGTikuLnalpaV+lwEAANAh\nM1vinCvu6DxGyAAACY9+Zkh0ns4hM7PzzWytma03s7kR7r/OzCrNbFn46wYv6wEAJJ+WfmbBmjo5\nHe5nVlIW9Ls0IGqeBTIzS5d0r6QLJI2XdJWZjY9w6p+cc5PDXw95VQ8AIDnRzwzJwMsRsmmS1jvn\nNjjnDkp6UtJMD18PAJCC6GeGZOBlICuQtKXV7fLwsfa+bGbLzewZMxsR6YnMbLaZlZpZaWVlpRe1\nAgASFP3MkAz87kP2Z0lFzrlJkl6W9LtIJznnHnTOFTvnigcPHtyjBQIA4hv9zJAMvAxkQUmtR7wK\nw8cOcc7tcs4dCN98SNJpHtYDAEhCs6YU6K5LJ6ogJyCTVJAT0F2XTmSVJRKKl20vFksaa2ajFQpi\nV0r6ausTzGy4c25r+OYlktZ4WA8AIEnNmlJAAENC8yyQOecazewWSQskpUt6xDm3yszulFTqnJsv\n6TtmdomkRklVkq7zqh4AAIB4Rad+AAAAj9CpHwAQEV3tgfhDIAOAFNLS1b6lkWpLV3tJhDLAR363\nvQAA9CC62gPxiUAGACmErvZAfCKQAUAKoas9EJ8IZACQQuhqD8QnJvUDQAppmbjPKkvvsIoVXUEg\nA4AUQ1d777CKFV3FJUsAAGKEVazoKgIZAAAxwipWdBWBDACAGGEVK7qKQAYAQIywihVdxaR+AABi\nhFWs6CoCGQAAMRRPq1hpwZE4CGQAACQhWnAkFgIZAABKvtGkY7Xg6MzvlWzvS7wikAEAUl4yjibF\nogVHMr4v8YpVlgCAlJeMDV1j0YIjlu9LSVlQZ9z9mkbPfVFn3P2aSsqCnX6OZEYgAwCkvGRs6BqL\nFhyxel9aRtqCNXVyOjzSRig7jEAGAEh5ydjQddaUAt116UQV5ARkkgpyArrr0omdutQYq/clGUcg\nY405ZACAlDdnxrg2c6Wk5Gjo2t0WHLF6X2I50pasCwwIZACAlEdD18hi9b7k5wQUjBC+OjPSluwL\nDMw553cNnVJcXOxKS0v9LgMAAESpfZiSQiNtnbmEesbdr0UMdQU5Ab0z9+yY1RprZrbEOVfc0XmM\nkAEAAE/FYqQtGRdetEYgAwAAnuvufLZYXPaMZ6yyBAAAcS8WbTxaxGNPNEbIAABA3IvVAoN4XRxA\nIAMAAAmhu5c9pdjt8RlrXLIEAAApI14XBxDIAABAyojXXRkIZAAAIGXEcnFALDGHDAAApIx43ZXB\n00BmZudLukdSuqSHnHN3t7u/t6THJJ0maZekK5xzm7ysCQAApLZYLA6INc8uWZpZuqR7JV0gabyk\nq8xsfLvTrpdU7ZwbI+l/JP2nV/UAAADEKy/nkE2TtN45t8E5d1DSk5JmtjtnpqTfhX9+RtI5ZmYe\n1gQAABB3vAxkBZK2tLpdHj4W8RznXKOkWkkDPawJAAAg7iTEKkszm21mpWZWWllZ6Xc5AAAAMeXl\npP6gpBGtbheGj0U6p9zMMiRlKzS5vw3n3IOSHpQkM6s0s82eVNzWIEk7e+B1UhHvrXd4b73F++sd\n3ltv8f56p6P3dlQ0T+JlIFssaayZjVYoeF0p6avtzpkv6WuS/iHpK5Jec865Yz2pc26wB7UewcxK\nnXPFPfFaqYb31ju8t97i/fUO7623eH+9E6v31rNA5pxrNLNbJC1QqO3FI865VWZ2p6RS59x8SQ9L\n+r2ZrZdUpVBoAwAASCme9iFzzr0k6aV2x37S6ud6SZd5WQMAAEC8S4hJ/T550O8CkhjvrXd4b73F\n++sd3ltv8f56JybvrXUwZQsAAAAeY4QMAADAZwSydszsfDNba2brzWyu3/UkGzPbZGYrzGyZmZX6\nXU8iM7NHzGyHma1sdSzPzF42s3Xh77l+1pjIjvL+3mFmwfDnd5mZXehnjYnKzEaY2UIzW21mq8zs\n1vBxPr/ddIz3ls9uDJhZlpktMrMPwu/vT8PHR5vZ++Hs8Ccz69Xp5+aS5WHh/Tc/kvQFhXYWWCzp\nKufcal8LSyJmtklSsXOOfjjdZGaflbRX0mPOuZPDx34uqco5d3f4HxS5zrl/9bPORHWU9/cOSXud\nc//lZ22JzsyGSxrunFtqZv0lLZE0S9J14vPbLcd4by8Xn91uC2/v2Nc5t9fMMiW9LelWSf8s6Tnn\n3JNm9oCkD5xz93fmuRkhayua/TeBuOCce1OhdjGttd4f9ncK/SFGFxzl/UUMOOe2OueWhn/eI2mN\nQlvp8fntpmO8t4gBF7I3fDMz/OUkna3QntxSFz+7BLK2otl/E93jJP3dzJaY2Wy/i0lCQ51zW8M/\nb5M01M9iktQtZrY8fEmTS2rdZGZFkqZIel98fmOq3Xsr8dmNCTNLN7NlknZIelnSx5JqwntyS13M\nDgQy9LQznXOnSrpA0s3hy0LwQHjXC+YkxNb9ko6XNFnSVkn/7W85ic3M+kl6VtJ3nXO7W9/H57d7\nIry3fHZjxDnX5JybrNCWkNMknRiL5yWQtRXN/pvoBudcMPx9h6TnFfowI3a2h+eQtMwl2eFzPUnF\nObc9/Me4WdJvxOe3y8Lzb56V9Lhz7rnwYT6/MRDpveWzG3vOuRpJCyWdLiknvCe31MXsQCBr69D+\nm+EVElcqtN8mYsDM+oYnmcrM+ko6T9LKYz8KndSyP6zC31/wsZak0xIWwr4kPr9dEp4Y/bCkNc65\nX7S6i89vNx3tveWzGxtmNtjMcsI/BxRaBLhGoWD2lfBpXfrsssqynfBS4F/q8P6b/+5zSUnDzI5T\naFRMCm3b9Ufe364zsycknSVpkKTtkm6XVCLpKUkjJW2WdLlzjonpXXCU9/cshS75OEmbJN3Yas4T\nomRmZ0p6S9IKSc3hwz9UaK4Tn99uOMZ7e5X47HabmU1SaNJ+ukKDWk855+4M///tSUl5ksokXeOc\nO9Cp5yaQAQAA+ItLlgAAAD4jkAEAAPiMQAYAAOAzAhkAAIDPCGQAAAA+I5ABSEhm9m74e5GZfTXG\nz/3DSK8FAF6h7QWAhGZmZ0n6vnPu4k48JqPVvnOR7t/rnOsXi/oAIBqMkAFISGa2N/zj3ZI+Y2bL\nzOx74Y1/55nZ4vBGyjeGzz/LzBaa2R8lLQ8fKwlvdL+qZbN7M7tbUiD8fI+3fi0LmWdmK81shZld\n0eq5XzezZ8zsQzN7PNwxHQCiktHxKQAQ1+aq1QhZOFjVOuemmllvSe+Y2d/D506TdLJzbmP49j85\n56rCW6AsNrNnnXNzzeyW8ObB7V2qULfzUxTq4L/YzN4M3zdF0gRJFZLekXSGpLdj/+sCSEaMkAFI\nNudJutbMlim0Fc9ASWPD9y1qFcYk6Ttm9oGk9ySNaHXe0Zwp6YnwJs3bJb0haWqr5y4Pb968TFJR\nTH4bACmBETIAycYkfds5t6DNwdBcs33tbp8r6XTn3H4ze11SVjdet/W+dU3i7yuATmCEDECi2yOp\nf6vbCyR9y8wyJcnMTjCzvhEely2pOhzGTpQ0vdV9DS2Pb+ctSVeE56kNlvRZSYti8lsASGn8Cw5A\nolsuqSl86fFRSfcodLlwaXhifaWkWREe9zdJ3zSz5ZLWKnTZssWDkpab2VLn3NWtjj8v6XRJH0hy\nkn7gnNsWDnQA0GW0vQAAAPAZlywBAAB8RiADAADwGYEMAADAZwQyAAAAnxHIAAAAfEYgAwAA8BmB\nDAAAwGcEMgAAAJ8RyAAAAHyWcFsnDRo0yBUVFfldBgAAQIeWLFmy0zk3uKPzEi6QFRUVqbS01O8y\nAAAAOmRmm6M5j0uWAAAAPiOQAQAA+IxABgAA4LOEm0MWSUNDg8rLy1VfX+93KZ7LyspSYWGhMjMz\n/S4FAADEiGeBzMwekXSxpB3OuZMj3G+S7pF0oaT9kq5zzi3tymuVl5erf//+KioqUuhpk5NzTrt2\n7VJ5eblGjx7tdzkAACSkkrKg5i1Yq4qaOuXnBDRnxjjNmlLga01eXrJ8VNL5x7j/Akljw1+zJd3f\n1Reqr6/XwIEDkzqMSZKZaeDAgSkxEggAgBdKyoK67bkVCtbUyUkK1tTptudWqKQs6GtdngUy59yb\nkqqOccpMSY+5kPck5ZjZ8K6+XrKHsRap8nsCAOCFeQs+VF1DU5tjdQ1NmrdgrU8Vhfg5h6xA0pZW\nt8vDx7a2P9HMZis0iqaRI0f2SHEAACB5bNy5TyVlQQVrIl9lqqip6+GK2kqIVZbOuQedc8XOueLB\ngztsdtvjampqdN9993X6cRdeeKFqamo8qAgAAFTuOaBH3t6omb9+W5//r9f1q9fWqXdG5OiTnxPo\n4era8nOELChpRKvbheFjnov1ZL6WQHbTTTe1Od7Y2KiMjKO/xS+99FKXXxMAABxp34FGLVi1TSXL\nKvTO+p1qanYaP3yAfnThSfriKfl6b8Mu3fbcijaXLQOZ6ZozY5yPVfsbyOZLusXMnpT0KUm1zrkj\nLlfGWstkvpb/EC2T+SR1OZTNnTtXH3/8sSZPnqzMzEz169dPw4cP17Jly7R69WrNmjVLW7ZsUX19\nvW699VbNnj1b0uFtoPbu3asLLrhAZ555pt59910VFBTohRdeUCDgb1oHACARNDQ16611lSopq9Df\nV29TfUOzCnMD+ubnjtOsyQUaO7T/oXNb/l8fb6sszTnnzRObPSHpLEmDJG2XdLukTElyzj0Qbnvx\na4VWYu6X9HXnXIebVBYXF7v2e1muWbNGJ510kiTpp39epdUVu4/6+LJPanSwqfmI473S0zRlZE7E\nx4zPH6DbvzjhqM+5adMmXXzxxVq5cqVef/11XXTRRVq5cuWh1hRVVVXKy8tTXV2dpk6dqjfeeEMD\nBw5sE8jGjBmj0tJSTZ48WZdffrkuueQSXXPNNRFfr/XvCwBAKnLOaekn1Sopq9CLK7aqat9B5fTJ\n1EUTh+tLUwp02qjcuFgIZ2ZLnHPFHZ3n2QiZc+6qDu53km726vWPJlIYO9bxrpg2bVqbPmG/+tWv\n9Pzzz0uStmzZonXr1mngwIFtHjN69GhNnjxZknTaaadp06ZNMasHAJDa4rHvVlet37FXLywL6oVl\nFfqkar96Z6Tp3PFD9aXJBfrsCYPV6yhzxOJdUnTqb+1YI1mSdMbdrykYYSVFQU5Af7rx9JjU0Ldv\n30M/v/7663rllVf0j3/8Q3369NFZZ50VsY9Y7969D/2cnp6uujp/V3sAAJKDF1N1etqO3fWa/0GF\nSpYFtTK4W2kmnTFmkL5zzljNmDBU/bMSf/eapAtkHZkzY1zMJ/P1799fe/bsiXhfbW2tcnNz1adP\nH3344Yd67733uvw6AAB01rwFayP23frZi2s0/biBGtK/t9LS/L+0196e+gb9beU2vbCsQu9+vFPN\nTppYkK0fX3SSLjklX0MGZPldYkylXCDzYjLfwIEDdcYZZ+jkk09WIBDQ0KFDD913/vnn64EHHtCk\nSZM0btw4TZ8+vdu/AwAA0ahvaIp4VUiSdu49oOl3varMdNOw7CwV5ASUnxNQQfgrPyeggtyA8rMD\nCvRK75F6DzY2642PKlVSFtQra7brQGOzRub10S2fH6NLJhdozJB+PVKHHzyb1O+Vjib1p4JU+30B\nAJ2zp75Bj7//iR5+e6Mq9xyIeM7Avr30vS+coGBNnSpq6hSsDn3ftrteze7Ic/NzAsrPyVJBTp/w\n93BgywloYN9eUU2gjzSX7ZJT8lW6uVoly4J6acVW1exvUF7fXrp40nDNnFygU0fmxMXk/K7yfVI/\nAADoWVX7DurRdzbq0Xc3aXd9o84cM0iXFRfqt29vVF3D4cVrgcx0/dvF4yNeHWpsata23fWqqKlX\nsGZ/+HsosG2o3Ke31u3U/oNtL4H2zkg7HNCyW42u5WSpMKePhmVn6aUVW4+Yy/b9pz/QHfNXqaau\nQYHMdJ03YahmTS7QmWMHKTM9MSfndxWBDACABLe1tk6/eXOjnlj0ieoamjRjwlDddNYYnTIi1M7p\nhCH9o56qk5GepsLcPirM7SMp74j7nXOqrWs4FNIqaurCo2yh4Pbath1HjMqZSSYdMfLW2OxU19Ck\n/7niFJ03fpj69k7dWJK6vzkAAAlu4859euD1j/VcWbmanTRzcr6+9bnj2zRClULzp2O1otLMlNOn\nl3L69NKE/OyI5xxobNK22noFq0NhLVhTp1++si7iuQcbm/WlKYUxqS2REcgAAEgwqypqdd/rH+uv\nK7YqIz1NV00bqW985jiNyOvjd2mSpN4Z6Ro1sK9GDTzcBurp0vKICwz83kMyXhDIAABIEIs3Vem+\nheu1cG2l+vXO0OzPHq9/OrNIQ/rHfwsIL9pOJRMCGQAAccw5pzc+qtR9Cz/Wok1VyuvbS98/7wT9\nn9OLlB1InIao8bqHZLwgkPmgX79+2rt3r99lAADiWFOz099WbtN9r6/Xqordys/O0u1fHK8rp47s\nsb5gsRbLuWzJJjUD2fKnpFfvlGrLpexC6ZyfSJMu97sqAEgK8bJvYrzU0VkHG5tVUhbUA298rA07\n9+m4QX31869M0qzJBQm7TyM6lnqBbPlT0p+/IzWEJxbWbgndlrocyubOnasRI0bo5ptDe6Xfcccd\nysjI0MKFC1VdXa2Ghgb97Gc/08yZM2PxGwBA3IqXfRPjpY7O2H+wUU8u2qLfvLVBW2vrNSF/gO67\n+lTNmDBM6XG4tRFiK/k69f91rrRtxdGfoHyx1BSha3F6b6lwauTHDJsoXXD3UZ+yrKxM3/3ud/XG\nG29IksbgszlxAAAgAElEQVSPH68FCxYoOztbAwYM0M6dOzV9+nStW7dOZtbtS5Z06gcQr06/61Vt\nra0/4njf3um6onhkj9Xxp9JPtO9A0xHHhw3I0rtzz46rvRtr9zfosX9s0m/f3aSqfQc1bXSebv78\nGH127KCE7lCPEDr1H02kMHas41GYMmWKduzYoYqKClVWVio3N1fDhg3T9773Pb355ptKS0tTMBjU\n9u3bNWzYsC6/DgDEm+2767VoY5VKN1Vp0abqiGFMkvYdaNLTpVt6rK5IYUyStu2u17h/+6uGZ7fa\nrzEn69AWQC3HsjK9n6O1Y0+9Hn57ox5/7xPtPdCos08copvOOl7FRUc2Y0XyS75AdoyRLEnS/5wc\nukzZXvYI6esvdvllL7vsMj3zzDPatm2brrjiCj3++OOqrKzUkiVLlJmZqaKiItXXR/5DBQCJwDmn\nDTv3hcLXxmot3lSlT6r2S5L69ErXqSNz1T8rQ3vqG494bEFOQO/MPbvHaj3j7tci9rzKDmTqqmkj\nD+3f+O7HO7U9wt6Ng/qF927MDrQJawXh/RzzurF342mjcvXgmxv0p9Itamxq1kWTQs1cx+cPiNWv\njwSUfIGsI+f8pO0cMknKDISOd8MVV1yhb3zjG9q5c6feeOMNPfXUUxoyZIgyMzO1cOFCbd68uZuF\nA0DPamxq1pqte7RoU5UWb6xS6eYq7dx7UJKU17eXikfl6trTR2lqUZ7G5w9QZnraEXO3JH96TR2t\n59VPL5lwxByyhqbmUFf5cEhr2QooWFOvdTv26I2PKts8jyRlZaa1CWktI2v5OQEV5gY0dEDkvRv/\n5akP1OycMtJNXzmtUDd+9ngVDeorIPUCWcvE/RivspwwYYL27NmjgoICDR8+XFdffbW++MUvqri4\nWJMnT9aJJ54Yg+IBwDv1DU0q+6RGizdVafGmKi3dXK194U2kC3MD+uzYwZo6Ok9Ti/J0/OC+EUeI\n4qXXVGfqyExP04i8Pkftcu+cU/X+hsNBrc3+jXVas3WPdu6Nbu/GJufUr3e6XvnnszQsO/6buaLn\nJN+k/hSQar8vAG/U7D+o0k3VhwLYimCtGpqczKRxQ/tralFeOIDlang229scS31Dk7aG925sCWv3\nvBp570aTtPHui3q2QPiGSf0AkGI66rtVUVN3KHwt3littdv3SJIy002TCnN0/ZnHadroXJ02Mk/Z\nfRKnA3w8yMpM1+hBfTW61eXHZ5awdyOiRyADgCQQqe/Wvz67XO98vFONTU6LNlYdCgf9emfo1FG5\nunjScE0dnafJI3J6ZFVhqmHvRnRG0gQy51xK9GtJtEvMALzVMiH9Zy+uPmLi+YHGZj1dWq5B/Xpp\nalGerj9ztKaNztOJw/orI52O716Ll/l0SAxJEciysrK0a9cuDRw4MKlDmXNOu3btUlYWE0GBVLG7\nvuHQvKSKmjqV19SpoqY+NE+puk7b99TrWP9OM0mLf3RuUv9tjGfs3YhoJUUgKywsVHl5uSorK/0u\nxXNZWVkqLCz0uwwArXR1z8SmZqcde0ITwYPhoBWs2R/6Hg5hew607enVKz1Nw3OylJ8d0JljB4Xa\nLOQE9J9/+1C79h084jXycwKEMSABJEUgy8zM1OjRo/0uA0AKOtaeiedNGBoa1apuNarVql3Cttp6\nNbbri5AdyFRBTkAj8vro9OMHKj8nq02/q0H9ekfc9qdXRhrzlYAElhSBDAD8Mm/B2iPmbtU1NOl7\nTy074lJieppp2IAsFeQEVDwq91AH+JZRruE5AfXr3bU/y8xXAhIbgQwAuqEiQlsDSXIutMqusNW2\nO0P69/Z0Mj3zlYDERSADgC5qbGpWn17ph7rZt1aQE9DNnx/jQ1UAEhHrngGgC2r3N+i63y7WvoNN\nymg3p4u5WwA6ixEyAOikDZV7dcPvSrWler9+/uVJ6pWRxtwtAN1CIAOATnh73U7d9PgSZaSn6fEb\npmva6DxJIoAB6BZPL1ma2flmttbM1pvZ3Aj3jzSzhWZWZmbLzexCL+sBgO547B+b9LXfLtLw7IBe\nuPmMQ2EMALrLsxEyM0uXdK+kL0gql7TYzOY751a3Ou3Hkp5yzt1vZuMlvSSpyKuaAKArGpqa9dM/\nr9If3vtE5540RL+8ckqX21MAQCRe/kWZJmm9c26DJJnZk5JmSmodyJykAeGfsyVVeFgPAHRazf6D\nuunxpXr341268XPH6QczTlR6hMasANAdXgayAklbWt0ul/SpdufcIenvZvZtSX0lnRvpicxstqTZ\nkjRy5MiYFwoAkazfsVc3/G6xKmrq9V+XnaKvnMa2ZQC84Xfbi6skPeqcK5R0oaTfm9kRNTnnHnTO\nFTvnigcPHtzjRQJIPW98VKkv3feO9h5o1BOzP0UYA+ApL0fIgpJGtLpdGD7W2vWSzpck59w/zCxL\n0iBJOzysCwCOyjmn376zST97cbVOGNpfD32tWIW5ffwuC0CS83KEbLGksWY22sx6SbpS0vx253wi\n6RxJMrOTJGVJqvSwJgA4qoONzfrh8yt0519W69yThurZb32aMAagR3g2QuacazSzWyQtkJQu6RHn\n3Cozu1NSqXNuvqR/kfQbM/ueQhP8r3Ou/Xa8AOC96n0H9c0/LNH7G6t001nH6/vnjVMak/cB9BBP\n1207515SqJVF62M/afXzaklneFkDAHRk3fY9uv53pdq2u16/vGIyTV4B9Dga6QBIaQs/3KFvP1Gm\nrMx0PTl7uk4dmet3SQBSEIEMQEpyzunhtzfqP15aoxOHDdBDXytWfk7A77IApCgCGYCUc7CxWT8u\nWaGnSst1/oRh+sUVp6hPL/4cAvAPf4EApJRdew/oW39YqkWbqvSds8fou+eewOR9AL4jkAFIGWu3\n7dH1v1usHXsO6J4rJ2vmZCbvA4gPBDIAKeHVNdv1nSfK1Kd3hp668XRNHpHjd0kAcAiBDEBSc87p\nN29t0F1//VAT8gfoN9cWa3g2k/cBxBcCGYBOKykLat6CtaqoqVN+TkBzZoyLy95dBxqb9KPnV+qZ\nJeW6aOJw/ddlpyjQK93vsgDgCAQyAJ1SUhbUbc+tUF1DkyQpWFOn255bIUlxFcp27j2gb/5+iUo3\nV+vWc8bq1nPGMnkfQNzyci9LAElo3oK1h8JYi7qGJv3n3z5UvOx8tmbrbs389TtaEazVr786Rd/7\nAispAcQ3RsgAdEpFTV3E41tr63Xy7QuUnxNQQW4g9L3lK3x7aP/eykj39t+Bf1+1Td/90zL1z8rQ\n0988XZMKmbwPIP4RyAB0Sn5OQMEIoWxAVoYuPbVQFTV1CtbU6YMtNare39DmnPQ007ABWcrPyVJB\nTiBieOvbO/o/S23nsmVpysgcvbhimyYVZOvBa4s1dEBWt39fAOgJBDIAnXL19JH6+d/WtjkWyEzX\nnTNPPmIO2b4DjdpaW6dgTb2C1XWqqAl9ldfUqXRztbYt36rG5raXObMDmYfCWmFuQPk5WW0C26B+\nvZWWZhHmstUrWLNNU0bk6InZ05WVyeR9AImDQAYganvqG/R0abn6905X396Z2r67/pirLPv2ztCY\nIf01Zkj/iM/X1Oy0Y099KKRV16mipl7Bmv2qqKlXefV+vb9hl/YcaGzzmF7paRqek6VttfU60Nh8\nxHPu2FNPGAOQcAhkAKLinNPcZ1fok6r9+uMNn9KnjhvY7edMTzMNzw5oeHZAp42KfM7u+oYjRtcq\nauq1eVdFxPMrauq7XRcA9DQCGYCoPPruJr24YqvmXnBiTMJYtAZkZWrA8EydNHxAm+NLN1dHnMuW\nn0PTVwCJh7YXADq0ZHO1/v3FNTr3pKGa/Znj/C5HkjRnxjgF2l2aDGSma86McT5VBABdxwgZgGOq\n2ndQt/xxqYbnZOm/Lzslbvp5tcxZS4QdAwCgIwQyAEfV1Ox065Nl2rXvoJ771qeV3SfT75LamDWl\ngAAGIClwyRLAUf36tfV6a91O3fHFCTq5INvvcgAgaRHIAET01rpK/fLVj3TplAJdNW2E3+UAQFIj\nkAE4wtbaOt365DKNHdJPP/vSyTKLj3ljAJCsCGQA2mhoatbNjy/VgYYm3X/NaerTi6mmAOA1/tIC\naOPuv36opZ/U6H+vmqLjB/fzuxwASAlRjZCZ2XNmdpGZMaIGJLG/rtiqh9/eqOs+XaQvnpLvdzkA\nkDKiDVj3SfqqpHVmdreZ0XkRSDIbd+7TnGeWa/KIHP3wwpP8LgcAUkpUgcw594pz7mpJp0raJOkV\nM3vXzL5uZvHVmAhAp9UdbNK3/rBEGemme68+Vb0yGAwHgJ4U9V9dMxso6TpJN0gqk3SPQgHtZU8q\nA9BjfvLCSq3dvke/vGKyCtgLEgB6XFST+s3seUnjJP1e0hedc1vDd/3JzEq9Kg6A955avEVPLynX\nd84eo7PGDfG7HABISdGusvyVc25hpDucc8UxrAdAD1pVUat/e2GlzhgzULeee4Lf5QBAyor2kuV4\nM8tpuWFmuWZ2k0c1AegBu+sbdNPjS5XTJ1P3XDlF6XGyaTgApKJoA9k3nHM1LTecc9WSvtHRg8zs\nfDNba2brzWzuUc653MxWm9kqM/tjlPUA6AbnnOY8/YHKq+t071dP1aB+vf0uCQBSWrSXLNPNzJxz\nTpLMLF1Sr2M9IHzOvZK+IKlc0mIzm++cW93qnLGSbpN0hnOu2syYwAL0gIff3qgFq7brxxedpOKi\nPL/LAYCUF+0I2d8UmsB/jpmdI+mJ8LFjmSZpvXNug3PuoKQnJc1sd843JN0bHnGTc25H9KUD6IrF\nm6p0118/1IwJQ3X9maP9LgcAoOhHyP5V0o2SvhW+/bKkhzp4TIGkLa1ul0v6VLtzTpAkM3tHUrqk\nO5xzRwQ9M5stabYkjRw5MsqSAbS3c+8B3fLHpSrMDWjeZaewaTgAxImoAplzrlnS/eGvWL/+WEln\nSSqU9KaZTWw9Xy38+g9KelCSiouLXYxrAFJCU7PTrU+WqWZ/g567aaoGZNHTGQDiRbR9yMZKukvS\neElZLcedc8cd42FBSSNa3S4MH2utXNL7zrkGSRvN7COFAtriaOoCEL17XvlI76zfpZ9/eZIm5Gf7\nXQ4AoJVo55D9VqHRsUZJn5f0mEJNYo9lsaSxZjbazHpJulLS/HbnlCg0OiYzG6TQJcwNUdYEIEoL\n1+7Qr15br8tOK9TlU0d0/AAAQI+KNpAFnHOvSjLn3Gbn3B2Szj7WA5xzjZJukbRA0hpJTznnVpnZ\nnWZ2Sfi0BZJ2mdlqSQslzXHO7erKLwIgsmBNnb73p2U6cVh/3TnzZL/LAQBEEO2k/gNmliZpnZnd\notClxw5bVDjnXpL0UrtjP2n1s5P0z+EvADF2sLFZNz2+VI1NTvdfc5oCvdL9LgkAEEG0I2S3Suoj\n6TuSTpN0jaSveVUUgNj4j5fW6IMtNZr3lUkaPaiv3+UAAI6iwxGycIPXy51zcyTtlfR1z6sC0G1/\n/qBCj767SdefOVoXTBzudzkAgGPocITMOdck6TSjYRGQMNbv2Ku5zy7XaaNyNfeCE/0uBwDQgWjn\nkJVJesHMnpa0r+Wgc+45T6oC0GX7DzbqpseXqHdmun791SnKTI92ZgIAwC/RBrI8SbvUdmWlk0Qg\nA+KIc04/en6l1u3Yq8f+aZqGZwf8LgkAEIVoO/UzbwxIAE8s2qLny4L63rkn6DNjB/tdDgAgStF2\n6v+tQiNibTjn/inmFQHokhXltbpj/ip99oTB+vbZY/wuBwDQCdFesvxLq5+zJH1JUkXsywHQFbX7\nG3TTH5doYL9e+uUVk5WWxhocAEgk0V6yfLb1bTN7QtLLnlQEoFOam53+5ell2lpTr6e+ebry+vby\nuyQAQCd1dfnVWEmjYlkIgK558K0NemXNDv3oopN06shcv8sBAHRBtHPI9qjtHLJtkv7Vk4oARO29\nDbs0b8FaXTRxuK77dJHf5QAAuijaS5b9vS4EQOfs2FOvbz9RplF5fXT3lyeK3s0AkLiiHSH7kqTX\nnHO14ds5ks5yzpV4WRyAI5WUBfXzBR+qoqZekvT1M4rUPyvT56oAAN0R7Ryy21vCmCQ552ok3e5N\nSQCOpqQsqNueW34ojEnS/766XiVlQR+rAgB0V7SBLNJ50bbMABADa7ft0Y9LVqquobnN8bqGJs1b\nsNanqgAAsRBtqCo1s19Iujd8+2ZJS7wpCUCLipo6zf+gQiVlQX24bc8xzwMAJK5oA9m3Jf2bpD8p\ntNryZYVCGYAYq61r0F9XbFXJsqDe31gl56TJI3L000sm6P43Pta22vojHpOfw56VAJDIol1luU/S\nXI9rAVJWfUOTFn64QyXLglr4YaUONjXruEF99d1zTtDMyfkqGtRXkpQdyNRtz61QXUPToccGMtM1\nZ8Y4v0oHAMRAtKssX5Z0WXgyv8wsV9KTzrkZXhYHJLPmZqf3Nu7SC2UVemnlVu2pb9Sgfr119fSR\n+tKUAk0syD6ilcWsKQWSpHkL1qqipk75OQHNmTHu0HEAQGKK9pLloJYwJknOuWozG+JRTUDScs5p\n9dbdemFZheYvq9C23fXq2ytdM04eplmTC/Tp4wcqI/3Ya21mTSkggAFAkok2kDWb2Ujn3CeSZGZF\natu5H8AxlFfv1wvLKvTCsqA+2r5XGWmmz50wWD+86CR94aShCvRK97tEAICPog1kP5L0tpm9Ickk\nfUbSbM+qApJA9b6DenHFVr2wLKjFm6olScWjcvV/Z52siyYOZxNwAMAh0U7q/5uZFSsUwsoklUhi\nnT3QTn1Dk15Zs10lZRV646MdamhyGjOkn75/3gmaOblAI/L6+F0iACAORTup/wZJt0oqlLRM0nRJ\n/5B0tnelAYmhqdnp3Y93qqSsQgtWbdPeA40a0r+3rvt0kWZOLtCE/AHsMwkAOKZoL1neKmmqpPec\nc583sxMl/dS7soD4U1IWbLW6MUtXTh2pmroG/fmDCu3Yc0D9e2fogpOHadaUAk0/bqDS0whhAIDo\nRBvI6p1z9WYmM+vtnPvQzGh8hJQR2kPycP+vYE29/vvlj5Rm0rknDdWsKQU6+8Qhyspkcj4AoPOi\nDWTlZpaj0Nyxl82sWlKFd2UB8WPX3gO6ff6qNs1YWwwdkKUHry32oSoAQDKJdlL/l8I/3mFmCyVl\nS/qbZ1UBPtt/sFEvr96uF5ZV6M2PKtXYHLnLS6RtjAAA6KxoR8gOcc694UUhgN8am5r1zse7VFIW\n1IJV27T/YJOGZ2fp+s+M1vNLg9qx58ARj2EPSQBALHQ6kAHJxDmnD8prVVIW1F+WV2jn3oMakJWh\nS07J16wpBZpWlKe0NNNJwwawhyQAwDMEMqSkjTv3qaQsqPkfVGjjzn3qlZGmc04copmTC/T5Ewer\nd0bbyfnsIQkA8JKngczMzpd0j6R0SQ855+4+ynlflvSMpKnOuVIva0LqqtxzQH9ZXqGSZRX6YEuN\nzKTpowfqm587TuefPFzZgcxjPp49JAEAXvEskJlZuqR7JX1BUrmkxWY23zm3ut15/RXqc/a+V7Ug\nde070Ki/r96m58sq9M76nWpqdho/fIB+eOGJ+uIp+RqezRwwAID/vBwhmyZpvXNugySZ2ZOSZkpa\n3e68/yvpPyXN8bAWpJCGpma9ta5SJWUVenn1dtU1NKkgJ6AbP3ucZk0p0AlD+/tdIgAAbXgZyAok\nbWl1u1zSp1qfYGanShrhnHvRzAhk6DLnnJZ+UqMXlgX1l+VbVbXvoHL6ZOrSU0OXGU8bmas0OucD\nAOKUb5P6zSxN0i8kXRfFubMV2thcI0eO9LYwJJT1O/bqhWVBvbCsQp9U7VfvjDSdO36oZk0u0OdO\nGKxeGWl+lwgAQIe8DGRBSSNa3S4MH2vRX9LJkl4Pb7w8TNJ8M7uk/cR+59yDkh6UpOLi4sgdOpNI\n2z0TWc3X/v248bOjdbDJ6YVlFVoRrFWaSWeMGaTvnDNWMyYMVf+sY0/OBwAg3phz3uQbM8uQ9JGk\ncxQKYoslfdU5t+oo578u6fsdrbIsLi52paXJuxCz/Z6JUqjf1V2XTkzJUBbp/WgxsSBbMyfn65JT\n8jVkQJYP1QEAcGxmtsQ51+Eee56NkDnnGs3sFkkLFGp78YhzbpWZ3Smp1Dk336vXTmTzFqw9InzU\nNTTp9vkrNWZIP500fIDSU2Au1Pbd9Vq0sUo/ej5yGBvSv7f+/O0zfagMAIDY83QOmXPuJUkvtTv2\nk6Oce5aXtSSKipq6iMdr6xp18f++rX69M3TqqFxNHZWrqaPzNHlEjrIy0yM+JlE457Rh5z4t3lil\nRZuqtHhTlbZURX4fWlRG2MYIAIBERaf+OHKgsUm9M9JU39h8xH3DBvTWbReepMWbqlS6qVq/eOUj\nOSdlppsmFeZoalGephblqnhUnrL7xPccqsamZq3euluLNlYd+n127TsoSRrYt5eKi3L1tdOLNG10\nnr75hyWqqDlyA2/2kAQAJBMCWZzYf7BRN/5+ieobm5WZbmpoOjy3L5CZrrkXnKSZkws0c3JoHlnt\n/gaVbg6NKJVuqtbDb2/QA284mUnjhvbX1KI8FRflatroPN+bn9YdbFLZlmot3lit0s1VWrq5WvsO\nhi5DjsgL6HPjBmtaUZ6mjs7TcYP6KrzIQ5L0gxknsockACDpeTap3yvJOKl/d32Drn90sZZsrtbd\nX56kXulpnV5lWd/QpGVbag5d9msdegpzA4cCz9SiXB0/uF+b0BNrNfsPavGmapVuCtWyMlirhqbD\nYXHa6LzwiF6ehmV3PBmfVacAgEQV7aR+ApnPqvcd1LWPLNKarbt1z5VTdNGk4TF53samZn24bc+h\ny4KLN1Vp597QZcG8vr1UPCo0elZclKcJ+QOUmd71fl3BmrpQ+Aq/1kfb90qSeqWnaVJh9qEgeNrI\n+L+cCgBALBHIEsCO3fW65uH3tWnXfj1wzak6+8Shnr2Wc04bd+5T6abqQxPnN+/aL0nq0ytdU0aG\n5qFNK8rT5JE56tMrI+LI1CWn5Ovjyr2h59hYpcWbqhUML0To1ztDp43K1dSiXE0tytMpSbDgAACA\n7iCQxbny6v265qH3tWPPAT30tWJ9+vhBPV7D9t31hybVL9pYpTXbdss5KSPNNDwnS1tr6tXYfPjz\nkWZSVkaa9jeEFh0M6tdb00bnHrr8mCotOQAAiJbvfchwdBsq9+qah97X3gON+sMNn9KpI3N9qWPo\ngCxdPClfF0/KlxSay7Zkc7UWb6zSQ29tbBPGJKnZSTLTz78ySdOK8jRqYB9P56IBAJAq2Oivh324\nbbcu/3/v6UBjs56YPd23MBbJgKxMfX7cEP3g/BPV0HRk6w0ptGLy8uIRKmq3GhIAAHQdgawHfbCl\nRlf8v/eUkWb6042na0J+tt8lHdXR+nzR/wsAgNgjkPWQ9zfs0tUPva8BgQw9/c3TNWZIP79LOqY5\nM8Yp0G5CPv2/AADwBnPIesAbH1Xqxt+XqiAnoMdvmB5V7y2/tfT5ov8XAADeI5B57G8rt+nbTyzV\n2CH99fvrp2lgv95+lxS1WVMKCGAAAPQAApmHni8r1/efXq5TCrP1269PU3aApqgAAOBIBDKPPP7+\nZv24ZKVOP26gfnNtsfr25q0GAACRkRI88OCbH+s/XvpQ55w4RPdefSrd6gEAwDERyGLIOadfvrJO\n97y6ThdNGq5fXjG5W3tEAgCA1EAgixHnnP79xTV66O2Nury4UHddOolthAAAQFQIZDHQ1Oz045KV\nemLRJ7ru00X6ycXjlUYYAwAAUSKQdVNDU7O+//QHemFZhW7+/PH6/nnj2FIIAAB0CoGsGw40NumW\nP5bp5dXb9YPzx+mms8b4XRIAAEhABLIu2n+wUTf+foneWrdTP71kgr726SK/SwIAAAmKQNYFu+sb\ndP2ji7Vkc7XmfWWSLise4XdJAAAggRHIOql630Fd+8girdm6W/971am6aNJwv0sCAAAJjkDWCTt2\n1+uah9/Xpl379eC1p+nsE4f6XRIAAEgCBLIolVfv1zUPva8dew7o0a9P1aePH+R3SQAAIEkQyKKw\noXKvrnnofe090Kg/3PApnToy1++SAABAEiGQdeDDbbt1zUOL5JzTE7Ona0J+tt8lAQCAJEMgO4YP\nttTo2kcWKZCZrj/cMF1jhvTzuyQAAJCECGTtlJQFNW/BWlXU1EmScvtm6ulvnq4ReX18rgwAACSr\nNL8LiCclZUHd9twKBWvq5CQ5SfsPNGnJ5mq/SwMAAEmMQNbKvAVrVdfQ1OZYfWOz5i1Y61NFAAAg\nFRDIWmm5TBntcfSQ5U9J/3OydEdO6Pvyp/yuCACAmPI0kJnZ+Wa21szWm9ncCPf/s5mtNrPlZvaq\nmY3ysp6O5OcEOnUcPWD5U9KfvyPVbpHkQt///B1CGQAkonj5B3a81NGKZ4HMzNIl3SvpAknjJV1l\nZuPbnVYmqdg5N0nSM5J+7lU90ZgzY5wCmeltjgUy0zVnxjifKoJe/anU0G6EsqFOevVOf+oB0LE4\n/J8d4kC8/AM7Xupox8tVltMkrXfObZAkM3tS0kxJq1tOcM4tbHX+e5Ku8bCeDs2aUiBJh1ZZ5ucE\nNGfGuEPH4bHGg1LlGmnbCmnrcmnbcqm2PPK5tVukXR9LA4/v2RoBHFvL/+xa/iHV8j87SZp0uX91\npbrlT4X+IVtbLmUXSuf8xJv/Hs5JB3ZL9bVSXY1UXxP+Xiv9/UeR/4H9l+9Kn7wnWZpkFvoua3Xb\n2t1Oi3BOy207ynO0uv36XUf/h76Pn1EvA1nB/2/vzoPjrO87jr+/lmTLko1k+ZCMD4wPDhsb7DqF\nxNMmwRwmB9AOJClHaUuaTpqkkDJNoUlImkkyzDQNadO0hCTENGFIU46GhgbMVTLMhHKYGGwDtjFg\ny5eMD/nC1vXtH79nvc9Ku7IsS/tbaT+vmZ19nmcfrb/78+7zfJ7fcwGbU+PNwLm9zH898Kt8L5jZ\npyGiMTAAABArSURBVIBPAUyfPn2g6svr8oVTFMCK4fA+2LE6G7y2vwwtr0FXe3i9qhaazoKRY6Dt\nQP73+O4iaJgFp10Mcy6EU5ZA5ajifQaRjGKt7EpZRxvsfRseuSX/yu6Rm6F2AoweB6MbwvOoscnK\nVgbV8Ybkzo4QoA6nA1UqWOUdzoy3gncdX31tB2Htf4Uw512AJ8Pp8a4848f57xxLoQ6AIimJ65CZ\n2TXAYuD9+V539zuBOwEWL17sRSxNTpQ77N8eer22r8r2fu15MztP7URoWgDvuwCa5kPT2dBwKoyo\n6LkgAagaDed/CUZUwfoV8PyP4Nl/DSFu5gfgtItg9oVQp2AtRVBOPUIdbbDnLdi9EXa/EZ53Jc+t\nm3tfQR7aBT/5g9xpVpEEtHFQ05AdPhra6vO/PuqkvgW5UgjKxaqhqws63g3fw7aD0H4oPNoOFQ7J\n/30DrP1Fz8DVtr/3f6tiJFTXh/+f6noYMwkmzElNq8t9vbouDN+1DPZt6fl+ddPg86v797kzwa1g\naMszfscS2Lc1Tx1T+1fDABnMQLYFmJYan5pMy2FmFwBfBN7v7kcGsR4ZbF1dYcG8fVXS8/VK6Pk6\nuDM7z7hTYfICWHh1CF6TF8CYxsIL18yCq9AC7dy/CAucN38dwtn6FfD6w+G1xvmh5+y0i2HKYqgo\nie0PGQ66OsP3cdcG+J+/yb+ye/imsOumdlLY6BiTPJd6r1DHEdjzds/AtfuN8JnToWtUHYyfCVPf\nAws+Hg4hWPFlONjS833HNMGVy+HdPcljd2p4DxzaHVaSO9aG8d5CgVUkYa1biEuHtp2vwcqfQGey\nWmndDA99NnyG0y+h5y6wPLvFeh3vwzyr7w+749Jh/aHPwcF3YNYHw7Kr/VBueMoZPpgErD4Mtx86\n/v/r9kOw+83QlvWnwOSzu4WpAsGqqp8nul3w1fwb2Etv7d/7QWqXJkBFr7Nm6/j7ga9jAJj74HQ4\nmVklsA5YSghizwNXufua1DwLCQfzL3P39X1538WLF/sLL7wwCBVLD71t2XUcgZa1ucFr++qwcIDQ\nezXpjBC6muaH4NU4L/ygB5N7WBCvexTWPwabfgPeGRYms5fCnIth9gVQO35w65Chzz306uzakPt4\nZ0MIKJ393H6srE5C2oRsSMs8Hx2eFJ6r62HEcZx71dfemI4j2Z6udODavbFn6KquC4cGjJ8FDTPD\ncMPM8Khp6BkuC/Vqf/Sfj69nqKMt6bVJBbZ0gOsR6PYcO8gNNZWjYWQNVCWPPg3XhvZOD99/PRzI\nE5JPpGeqv0qh17LIdZjZi+6++JjzDVYgS4r4EPAdQmy9y92/YWZfA15w94fM7HFgPrAt+ZNN7n5p\nb++pQFYk+RaqI6pCT9ORffDO69DVEaaPHJsNXU3zw+7HiWdA5cg4tae9uxc2PgXrVsCGx5LeOoOp\ni2HOReHRtOD4VnpSOgvVgXDkQAgjuzaEcJIOX4dbs/ONqAq70sfPzn3c/0nYX2D3xyefDL1FB1rC\nd+9ASxg/+E52+MDO8Jp39nyPEZVQMwHGTMyGtNoJqeFUmHvjf+HhG3N/s5XVsPh6OOnkVI/XxuzZ\nZRnV9T0DV2a8puH42zTm96OzPfzuvzWHnM+YduXy1O6sPuzi6vW4pkJ/4/DU1wvXecWPU+GpNglV\nqeHK0QO3XBqokCz9UhKBbDAokA2izo6wEmpZE44tOJJnS9NGhB6mTPCavADqZwyNQNPVBdteCj1n\n6x6FrSvD9DGNYdfmnItg5geh+qS4dZa6Ulq497lHKDngPKe3Kwlf+7flzls3LYSRnOA1C+qm59/t\nPRDt0dUVeoOOhrQkwB0Ncd2e+9M7N3pc/sDV39BV6m4/Kwme3RSzV6gUasgYThtRQ4wCmRTmHhbq\nO1aH3Y471oThnev6sKA3+OreopQ56A60wIbHw3FnG56EI62hR2L6e5MzNy+CCadld8logRZ8ex7s\ny3M2Us14uPS7oQ0zj4qqPONV4YSNo6+lxzPT+hDw8wWhymo47y/DCR3p3q49b+f2QNWMzw1bmeGG\nmf07PqaY3w33sLGU0+O2MxyzlpfBFzYOz9DVm1LYcCiFGiQ6BTIJ2g6FY6p2rEnC1+owfGhXdp6x\nk8PxXZPmQuNZ0DgX7v1E/lOAY2zZFUNnO2x+DtYnx561JJfLqz8lBLOq0fDcD8JZTBnDccHqHnan\ntW5OHs2wNzXcujn3uzNYbEQqrFWGnqnMeGZ4z1vZ3eb5VNXk6emarR6hclIKG1GlUINEpUBWbrq6\nYO9b4QylTI9Xy9rQS5A5jqKqBiadmYSveeG5cV7+lVO5b9nt3RSC2foVsPHp3CCWVjMe/vAHqbOQ\nkjORBvOMzhNZwHe0hd6to0GrOTd8tTZDx+Hcv6mqhfpp4d+qmwqrHwy9id2NaYKrfx52fXd1hGvK\ndXUUGM8Mt4czFnPGO3oOd5+3sx3WPFDgQxr89dqwoVHKZzMOtHL/zYqUKAWyoexYK9xDu5PerlSP\nV8ur2TMcsXDwceO80OM1aW4YHnfq4JyxNdy1H4ZvNFHwAOF8Ro7NniKePl38WKeTV9dDVXXh9+1t\npTv/ynAcUk7Y2pQNWns3w4EdPT/HmMbQi5IJXPXTk+Fk2uhxucGmVFb86hHqSb9ZkZKjQDZU5VvZ\nVYyEmeeHY2B2rMk9o2v0uGQ347xsz9ekM8LZOzJwCq38M9dWOtbVq9PDhe48kFExqnB4W/WzcJZr\ndyMqw/FT3d+7YlQSsqalQlYqfNVN7d/dDUphxV8qwVBEpBcKZENNV2c41mv5h8O1dPJpnB+O70qH\nr7FN5bVbJpaBXPl3tqdCWisc3tO3W5Jkhgs599M9w1ftxOH9/SiFYCgi0ou+BjJdujwG93DroC0r\nYetLsOVF2LbqGFdaNvj0M0UrUbo51h0DjkdFVXItqQnH/7e3zyt8ssUltx3/+w11Cz6mACYiw4IC\nWTHs356Er5UhfG19KdsLVlkdrue16I/h5EXw+K1h/u4i32NLKI2V/9KvlOQtP0RE5MQokA20d/eG\nwLV1ZQhhW1Zmj/myinCA/ZkfDeFryqIwXlGV/XszrXClsIHsqRMRkZKhQHYi2t8N93LM9HxtWRlu\nT5LRMAtmLMmGr6YF4ZYYvdEKV46lFHrqRERkQCmQdVfoIOHO9nBpiXTPV8va7NW/x54cQtc5V4Xn\nkxeGMyD7QytcERGRsqKzLNPy3lC7MtzDbv/W7AUzq+uT0LUo+3zS5MGpSURERIYsnWXZH098LTeM\nQbhC+L5meM+fZ3u+GmYO70sJiIiISFEpkKXlu5wAhN2Vy75Z3FpERESkbBzHfXTKQKFLS+iSEyIi\nIjKIFMjSlt4aLjGRpktOiIiIyCBTIEtb8LFwK5y6aYCFZ90XT0RERAaZjiHrTpecEBERkSJTD5mI\niIhIZApkIiIiIpEpkImIiIhEpkAmIiIiEtmQu3WSme0E3i7CPzUBeKcI/85QoLbIpfbIUlvkUnvk\nUntkqS1ylVN7nOLuE48105ALZMViZi/05d5T5UBtkUvtkaW2yKX2yKX2yFJb5FJ79KRdliIiIiKR\nKZCJiIiIRKZAVtidsQsoIWqLXGqPLLVFLrVHLrVHltoil9qjGx1DJiIiIhKZeshEREREIlMgExER\nEYlMgawbM1tmZq+b2QYzuzl2PTGZ2TQze8rM1prZGjO7IXZNsZlZhZm9ZGa/jF1LbGZWb2b3mdlr\nZvaqmb03dk0xmdnnk9/JajO718yqY9dUTGZ2l5m1mNnq1LQGM3vMzNYnz+Ni1lgsBdriH5Lfystm\n9qCZ1cessZjytUfqtZvMzM1sQozaSokCWYqZVQDfAy4B5gJ/ZGZz41YVVQdwk7vPBc4DPlPm7QFw\nA/Bq7CJKxD8Bj7j7GcDZlHG7mNkU4K+Axe5+FlABfCJuVUW3HFjWbdrNwBPuPgd4IhkvB8vp2RaP\nAWe5+wJgHXBLsYuKaDk92wMzmwZcBGwqdkGlSIEs1+8CG9x9o7u3AT8DLotcUzTuvs3dVybD+wkr\n3Clxq4rHzKYCHwZ+GLuW2MysDvh94EcA7t7m7nvjVhVdJTDazCqBGmBr5HqKyt1/DezuNvky4O5k\n+G7g8qIWFUm+tnD3Fe7ekYw+C0wtemGRFPhuANwOfAHQ2YUokHU3BdicGm+mjANImpnNABYC/xe3\nkqi+Q1h4dMUupAScCuwEfpzswv2hmdXGLioWd98CfIuwpb8NaHX3FXGrKgmN7r4tGd4ONMYspoT8\nGfCr2EXEZGaXAVvcfVXsWkqFApkck5mNAe4HbnT3fbHricHMPgK0uPuLsWspEZXAIuDf3H0hcJDy\n2R3VQ3Js1GWEoHoyUGtm18StqrR4uMZS2feEmNkXCYeD3BO7lljMrAb4O+DW2LWUEgWyXFuAaanx\nqcm0smVmVYQwdo+7PxC7noiWAJea2VuEXdnnm9lP45YUVTPQ7O6ZHtP7CAGtXF0AvOnuO929HXgA\neF/kmkrBDjObDJA8t0SuJyoz+xPgI8DVXt4XAZ1F2HhZlSxTpwIrzawpalWRKZDleh6YY2anmtlI\nwkG5D0WuKRozM8IxQq+6+7dj1xOTu9/i7lPdfQbhe/Gku5dtD4i7bwc2m9npyaSlwNqIJcW2CTjP\nzGqS381Syvgkh5SHgOuS4euAX0SsJSozW0Y45OFSdz8Uu56Y3P0Vd5/k7jOSZWozsChZrpQtBbKU\n5IDLzwKPEhamP3f3NXGrimoJcC2hN+i3yeNDsYuSkvE54B4zexk4B/hm5HqiSXoK7wNWAq8Qlq1l\ndWsYM7sX+A1wupk1m9n1wG3AhWa2ntCLeFvMGoulQFv8CzAWeCxZlt4RtcgiKtAe0o1unSQiIiIS\nmXrIRERERCJTIBMRERGJTIFMREREJDIFMhEREZHIFMhEREREIlMgExHpIzP7gJn9MnYdIjL8KJCJ\niIiIRKZAJiLDjpldY2bPJRfg/L6ZVZjZATP7RzNbaWZPmNnEZN5zzOxZM3vZzB5M7kuJmc02s8fN\nbFXyN7OStx9jZveZ2Wtmdk9yZX4RkROiQCYiw4qZnQl8HFji7ucAncDVQC2w0t0XAU8DX0n+5N+B\nv3X3BYSr7Gem3wN8z93PJtyXclsyfSFwIzAXmEm4o4WIyAmpjF2AiMgAWwr8DvB80nk1mnBT6y7g\nP5J5fgo8YGZ1QL27P51Mvxv4TzMbC0xx9wcB3P0wQPJ+z7l7czL+W2AG8MzgfywRGc4UyERkuDHg\nbne/JWei2Ze7zdff+8YdSQ13ouWoiAwA7bIUkeHmCeAKM5sEYGYNZnYKYXl3RTLPVcAz7t4K7DGz\n30umXws87e77gWYzuzx5j1FmVlPUTyEiZUVbdiIyrLj7WjP7ErDCzEYA7cBngIPAPDN7EWglHGcG\ncB1wRxK4NgJ/mky/Fvi+mX0teY8ri/gxRKTMmHt/e+1FRIYOMzvg7mNi1yEiko92WYqIiIhEph4y\nERERkcjUQyYiIiISmQKZiIiISGQKZCIiIiKRKZCJiIiIRKZAJiIiIhLZ/wOFUIHCrF1dSgAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa88d278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(solver.train_acc_history, '-o')\n",
    "plt.plot(solver.val_acc_history, '-o')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

